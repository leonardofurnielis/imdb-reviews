{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trusted AI IBM-Azure usecase: monitoring Azure model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build & Deploy** Machine Learning model in **Azure Machine Learning Studio**\n",
    "\n",
    "**Monitor** the model in **IBM Watson OpenScale**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Set up the environment](#setup_environment)\n",
    "1. [Explore and prepare training data](#explore_prepare_data)\n",
    "1. [Create train and test dataset](#train_test_set)\n",
    "1. [Train the model](#train_model)\n",
    "1. [Save the model in Azure](#save_model)\n",
    "1. [Create a custom entry script](#custom_score_script)\n",
    "1. [Create an online endpoint](#create_endpoint)\n",
    "1. [Create a custom environment for python](#create_custom_environment)\n",
    "1. [Deploy and score in Azure](#deploy_model)\n",
    "1. [Configure IBM OpenScale](#configure_openscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ibm_cloud_sdk_core\n",
    "%pip install ibm-watson-openscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup_environment\"></a>\n",
    "## 1. Set up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IBM credentials**\n",
    "\n",
    "To authenticate to IBM Watson OpenScale in the IBM Cloud, you need api_key and service location.\n",
    "\n",
    "Using [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) or directly through the IBM Cloud portal.\n",
    "\n",
    "Using IBM Cloud CLI:\n",
    "\n",
    "```\n",
    "ibmcloud login\n",
    "ibmcloud iam api-key-create API_KEY_NAME\n",
    "```\n",
    "\n",
    "NOTE: To get the Service URL [Endpoint URLs section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning).\n",
    "\n",
    "**Action**: Enter your api_key and location in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IBM_API_KEY = 'API_KEY'\n",
    "\n",
    "WOS_DB_CREDENTIALS=None\n",
    "WOS_SCHEMA_NAME = 'azure_dm'\n",
    "\n",
    "IBM_IAM_URL=\"https://iam.ng.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AZURE_ENGINE_CREDENTIALS =  {\n",
    "    \"client_id\": 'CLIENT_ID',\n",
    "    \"client_secret\": 'CLIENT_SECRET',\n",
    "    \"tenant\": 'TENANT',\n",
    "    \"subscription_id\": 'SUBSCRIPTION_ID'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore_prepare_data\"></a>\n",
    "## 2. Explore and prepare training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: read from `/data` directory if running locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/credit_risk_training.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Columns: ', list(df.columns))\n",
    "print('Number of columns: ', len(df.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train_test_set\"></a>\n",
    "## 3. Create train and test dataset\n",
    "\n",
    "NOTE: Test dataset (20%) and Training dataset (80%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_idx = np.s_[0:-1]\n",
    "all_records_idx = np.s_[:]\n",
    "first_record_idx = np.s_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_fields = [type(fld) is str for fld in train_data.iloc[first_record_idx, features_idx]]\n",
    "ct = ColumnTransformer([(\"ohe\", OneHotEncoder(), list(np.array(train_data.columns)[features_idx][string_fields]))])\n",
    "clf_linear = SGDClassifier(loss='log_loss', penalty='l2', max_iter=1000, tol=1e-5)\n",
    "\n",
    "pipeline = Pipeline([('ct', ct), ('clf_linear', clf_linear)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"train_model\"></a>\n",
    "## 4. Train the model\n",
    "\n",
    "Create a Scikit-learn models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Scikit Credit Risk Model Azure ML\"\n",
    "MODEL_NAME_SHORT = 'azure_credit_risk_model'\n",
    "DEPLOYMENT_NAME = \"Scikit Credit Risk Deployment Azure ML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_model = pipeline.fit(train_data.drop('Risk', axis=1), train_data.Risk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "predictions = risk_model.predict(test_data.drop('Risk', axis=1))\n",
    "indexed_preds = [0 if prediction=='No Risk' else 1 for prediction in predictions]\n",
    "\n",
    "real_observations = test_data.Risk.replace('Risk', 1)\n",
    "real_observations = real_observations.replace('No Risk', 0).values\n",
    "\n",
    "auc = roc_auc_score(real_observations, indexed_preds)\n",
    "\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(risk_model, '../model/' + MODEL_NAME_SHORT+ \".pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"save_model\"></a>\n",
    "## 5. Save the model in Azure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-ml azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AZURE_CLIENT_ID\"] = AZURE_ENGINE_CREDENTIALS[\"client_id\"]\n",
    "os.environ[\"AZURE_TENANT_ID\"] = AZURE_ENGINE_CREDENTIALS[\"tenant\"]\n",
    "os.environ[\"AZURE_CLIENT_SECRET\"] = AZURE_ENGINE_CREDENTIALS[\"client_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate\n",
    "# https://learn.microsoft.com/en-us/azure/machine-learning/how-to-setup-authentication?view=azureml-api-2&tabs=sdk\n",
    "\n",
    "credential = DefaultAzureCredential()\n",
    "\n",
    "# credential.get_token(\"https://management.azure.com/.default\")\n",
    "\n",
    "# Get a handle to the workspace\n",
    "az_ml_client = MLClient(\n",
    "    credential=credential,\n",
    "    subscription_id=AZURE_ENGINE_CREDENTIALS[\"subscription_id\"],\n",
    "    resource_group_name=\"watsonx_governance\",\n",
    "    workspace_name=\"ml_integration\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = az_ml_client.workspaces.get('ml_integration')\n",
    "print(\"LOCATION:\", ws.location, \"NAME:\", ws.name, \"RESOURCE_GROUP:\", ws.resource_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "file_model = Model(\n",
    "    path='../model/'+MODEL_NAME_SHORT+'.pkl',\n",
    "    type=AssetTypes.CUSTOM_MODEL,\n",
    "    name=MODEL_NAME_SHORT,\n",
    "    description='Random Forest Model to classify credit risk with probability',\n",
    "\n",
    ")\n",
    "\n",
    "az_ml_client.models.create_or_update(file_model)\n",
    "\n",
    "print('Name:', file_model.name)\n",
    "print('Version:', file_model.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick the latest version of the model\n",
    "latest_model_version = max(\n",
    "    [int(m.version) for m in az_ml_client.models.list(name=MODEL_NAME_SHORT)]\n",
    ")\n",
    "print(f'Latest model is version \"{latest_model_version}\" ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"custom_score_script\"></a>\n",
    "## 6. Create a custom entry script for the scoring response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ../script/azure_score.py\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def init():\n",
    "    \"\"\"\n",
    "    This function is called when the container is initialized/started, typically after create/update of the deployment.\n",
    "    You can write the logic here to perform init operations like caching the model in memory\n",
    "    \"\"\"\n",
    "    global model\n",
    "    model_path = os.path.join(str(os.getenv(\"AZUREML_MODEL_DIR\")), \"azure_credit_risk_model.pkl\") \n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    print(\"===> Init complete\")\n",
    "\n",
    "def run(input_payload):\n",
    "    \"\"\"\n",
    "    This function is called for every invocation of the endpoint to perform the actual scoring/prediction.\n",
    "    In the example we extract the data from the json input and call the scikit-learn model's predict()\n",
    "    method and return the result back\n",
    "    \"\"\"\n",
    "    print(\"===> Request received\")\n",
    "    try:\n",
    "        if type(input_payload) is str:\n",
    "            dict_data = json.loads(input_payload)\n",
    "        else:\n",
    "            dict_data = input_payload\n",
    "\n",
    "        data = pd.DataFrame.from_dict(dict_data[\"input\"])\n",
    "        predictions = model.predict(data)\n",
    "        scores = model.predict_proba(data)\n",
    "        risk_column = []\n",
    "        proba_column = []\n",
    "        proba_vector = []\n",
    "\n",
    "        for pred, proba in zip(predictions, scores):\n",
    "            risk_column.append(pred)\n",
    "            proba_vector.append([proba[0], proba[1]])\n",
    "            if pred == \"No Risk\":\n",
    "                proba_column.append(proba[0])\n",
    "            else:\n",
    "                proba_column.append(proba[1])\n",
    "        data[\"Scored Labels\"] = risk_column\n",
    "        data[\"Scored Probabilities\"] = proba_column\n",
    "        data[\"ProbabilityVector\"] = proba_vector\n",
    "\n",
    "        result = { \"output\": data.to_dict('records') }\n",
    "        print(\"===> Request processed\")\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        result = str(e)\n",
    "        return { \"error\": result }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_endpoint\"></a>\n",
    "## 7. Create an online endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "# Creating a unique name for the endpoint\n",
    "online_endpoint_name = MODEL_NAME_SHORT + '_' + str(uuid.uuid4())[:8]\n",
    "online_endpoint_name = online_endpoint_name.replace('_', '-')\n",
    "\n",
    "print(online_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect the endpoint creation to take a few minutes\n",
    "\n",
    "from azure.ai.ml.entities import (\n",
    "    ManagedOnlineEndpoint,\n",
    "    ManagedOnlineDeployment,\n",
    "    Environment,\n",
    "    CodeConfiguration,\n",
    ")\n",
    "\n",
    "# create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name, \n",
    "    description=\"This is a sample online endpoint\",\n",
    "    auth_mode=\"key\"\n",
    ")\n",
    "\n",
    "endpoint = az_ml_client.online_endpoints.begin_create_or_update(endpoint).result()\n",
    "\n",
    "print(f\"Endpoint {endpoint.name} provisioning state: {endpoint.provisioning_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = az_ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "\n",
    "print(\n",
    "    f'Endpoint \"{endpoint.name}\" with provisioning state \"{endpoint.provisioning_state}\" is retrieved'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"create_custom_environment\"></a>\n",
    "## 8. Create a custom environment for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = Environment(\n",
    "    name=\"azure-sklearn1-3-env\",\n",
    "    description=\"Environment created from a Docker image plus Conda environment\",\n",
    "    conda_file=\"../az-environment/conda.yaml\",\n",
    "    image=\"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:latest\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_ml_client.environments.create_or_update(environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick the latest version of the environment\n",
    "latest_env_version = max(\n",
    "    [int(m.version) for m in az_ml_client.environments.list(name=\"azure-sklearn1-3-env\")]\n",
    ")\n",
    "print(f'Latest model is version \"{latest_env_version}\" ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = az_ml_client.environments.get(name=\"azure-sklearn1-3-env\", version=latest_env_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deploy_model\"></a>\n",
    "## 9. Deploy and score in Azure\n",
    "\n",
    "NOTE: Deploy and score the model deployed at Azure ML Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model = az_ml_client.models.get(name=MODEL_NAME_SHORT, version=latest_model_version)\n",
    "\n",
    "blue_deployment = ManagedOnlineDeployment(\n",
    "    name=\"blue\",\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=model,\n",
    "    instance_type=\"Standard_D2as_v4\", # Standard_DS3_v2\n",
    "    instance_count=1,\n",
    "    environment=environment,\n",
    "    code_configuration=CodeConfiguration(\n",
    "        code=\"../script\", scoring_script=\"azure_score.py\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "blue_deployment = az_ml_client.begin_create_or_update(blue_deployment).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the deployment with some sample data\n",
    "import json\n",
    "\n",
    "with open('./azure_credit_risk_input_data.json', 'w') as f:\n",
    "    json.dump({'input': train_data.drop('Risk', axis=1)[-1:].to_dict('records')}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = az_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=\"blue\",\n",
    "    request_file=\"./azure_credit_risk_input_data.json\",\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete `azure_credit_risk_input_data.json` file from filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('./azure_credit_risk_input_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configure_openscale\"></a>\n",
    "## 10. Configure IBM OpenScale\n",
    "\n",
    "https://client-docs.aiopenscale.cloud.ibm.com/html/index.html#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "from ibm_watson_openscale import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "\n",
    "authenticator = IAMAuthenticator(\n",
    "        apikey=IBM_API_KEY\n",
    "    )\n",
    "\n",
    "wos_client = APIClient(authenticator=authenticator)\n",
    "\n",
    "print('Watson OpenScale on IBM Cloud!')\n",
    "print(wos_client.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 DataMart setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "\n",
    "if len(data_marts) == 0:\n",
    "    if WOS_DB_CREDENTIALS is not None:\n",
    "        if WOS_SCHEMA_NAME is None: \n",
    "            print(\"Please specify the SCHEMA_NAME and rerun the cell\")\n",
    "\n",
    "        print('Setting up external datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\",\n",
    "                database_configuration=DatabaseConfigurationRequest(\n",
    "                  database_type=DatabaseType.POSTGRESQL,\n",
    "                    credentials=PrimaryStorageCredentialsLong(\n",
    "                        hostname=WOS_DB_CREDENTIALS['hostname'],\n",
    "                        username=WOS_DB_CREDENTIALS['username'],\n",
    "                        password=WOS_DB_CREDENTIALS['password'],\n",
    "                        db=WOS_DB_CREDENTIALS['database'],\n",
    "                        port=WOS_DB_CREDENTIALS['port'],\n",
    "                        ssl=True,\n",
    "                        sslmode=WOS_DB_CREDENTIALS['sslmode'],\n",
    "                        certificate_base64=WOS_DB_CREDENTIALS['certificate_base64']\n",
    "                    ),\n",
    "                    location=LocationSchemaName(\n",
    "                        schema_name= WOS_SCHEMA_NAME\n",
    "                    )\n",
    "                )\n",
    "             ).result\n",
    "    else:\n",
    "        print('Setting up internal datamart')\n",
    "        added_data_mart_result = wos_client.data_marts.add(\n",
    "                background_mode=False,\n",
    "                name=\"WOS Data Mart\",\n",
    "                description=\"Data Mart created by WOS tutorial notebook\", \n",
    "                internal_database = True).result\n",
    "        \n",
    "    data_mart_id = added_data_mart_result.metadata.id\n",
    "    \n",
    "else:\n",
    "    data_mart_id=data_marts[0].metadata.id\n",
    "    print('Using existing datamart {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 Add service provider Azure Machine Learning Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_PROVIDER_NAME = \"Azure Machine Learning Service\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = \"Added by Azure Machine Learning Studio notebook.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.AZURE_MACHINE_LEARNING,\n",
    "        credentials=AzureCredentials(\n",
    "            subscription_id= AZURE_ENGINE_CREDENTIALS['subscription_id'], \n",
    "            client_id = AZURE_ENGINE_CREDENTIALS['client_id'], \n",
    "            client_secret= AZURE_ENGINE_CREDENTIALS['client_secret'],\n",
    "            tenant = AZURE_ENGINE_CREDENTIALS['tenant']\n",
    "        ),\n",
    "        background_mode=False\n",
    "    ).result\n",
    "\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.service_providers.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset_deployment_details = wos_client.service_providers.list_assets(data_mart_id=data_mart_id, service_provider_id=service_provider_id).result\n",
    "print(asset_deployment_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
