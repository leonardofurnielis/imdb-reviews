{"cells":[{"cell_type":"markdown","metadata":{"collapsed":true},"source":["# IMDB reviews sentiment analyses"]},{"cell_type":"markdown","metadata":{},"source":["This notebook uses Kaggle dataset (https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews)."]},{"cell_type":"markdown","metadata":{},"source":["### Contents"]},{"cell_type":"markdown","metadata":{},"source":["1. [Import dataset](#import_dataset)\n","1. [Explore data](#explore_data)\n","1. [Data preparation](#data_preparation)\n","1. [Create train and test dataset](#train_test_set)\n","1. [Create a model](#create_model)\n","1. [Publish the model](#publish_model)\n","1. [Deploy and score](#deploy_model)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install nltk"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%matplotlib inline \n","\n","import pandas as pd\n","import numpy as np\n","import matplotlib as mlp\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import json\n","\n","from nltk.stem import PorterStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import preprocessing\n","from sklearn import tree\n","from sklearn import svm\n","from sklearn import ensemble\n","from sklearn import neighbors\n","from sklearn import linear_model\n","from sklearn import metrics"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import nltk\n","nltk.download('stopwords')\n","nltk.download('punkt')"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"import_dataset\"></a>\n","## 1. Import dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# The code was removed by IBM Watson Studio for sharing."]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"explore_data\"></a>\n","## 2. Explore data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = df_data_1\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ax = sns.countplot(x=\"sentiment\", data=df)\n","plt.title(\"Sentiment label distribution\")"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"data_preparation\"></a>\n","## 3. Data preparation"]},{"cell_type":"markdown","metadata":{},"source":["In this step you will prepare data for training a model. Using the following Text Feature Engineering techniques:\n","\n","1. Tonkenization         \n","2. Removes stop words\n","3. Stemming text (porter)\n","4. Joining words (tokens) into a single string"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["stop_words = stopwords.words('english')\n","porter_stemmer = PorterStemmer()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def identify_tokens(row):\n","    \"\"\"Identify tokens in a row\n","    Args:\n","        row (list): row of dataframe\n","    \n","    Returns:\n","        list: text splited in tokens\n","    \"\"\"\n","    source = row[0]\n","    tokens = word_tokenize(source)\n","    token_words = [w for w in tokens if w.isalpha()]\n","    return token_words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def remove_stops(row):\n","    \"\"\"Remove stop words from text\n","    Args:\n","        row (list): row of dataframe\n","    \n","    Returns:\n","        list: list of tokens without stop words\n","    \"\"\"\n","    source_tokenization = row[2]\n","    stop = [w for w in source_tokenization if not w in stop_words]\n","    return (stop)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def stem_porter(row):\n","    \"\"\"Execute steamming porter\n","    Args:\n","        row (list): row of dataframe\n","    \n","    Returns:\n","        list: list of tokens with steamming.\n","    \"\"\"  \n","    my_list = row[2]\n","    stemmed_list = [porter_stemmer.stem(word) for word in my_list]\n","    return (stemmed_list)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def rejoin_words(row):\n","    \"\"\"Join tokens in a single string\n","    Args:\n","        row (list): row of dataframe\n","    \n","    Returns:\n","        str: text of joined tokens\n","    \"\"\"   \n","    my_list = row[2]\n","    joined_words = (\" \".join(my_list))\n","    return joined_words"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def pre_processing(df):\n","    \"\"\"Execute text feature engineering (TFE)\n","    Args:\n","        df (dataframe): row of dataframe\n","    \n","    Returns:\n","        list: Text post text feature engineering (TFE)\n","    \"\"\"  \n","    print('Tokenization ...')\n","    df['text1'] = df.apply(identify_tokens, axis=1)\n","    print('Removing stop words ...')\n","    df['text1'] = df.apply(remove_stops, axis=1)\n","    print('Stemming (porter) ...')\n","    df['text1'] = df.apply(stem_porter, axis=1)\n","    print('Joining words ...')\n","    df['clean_text'] = df.apply(rejoin_words, axis=1)\n","    print('DONE!')\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df = pre_processing(df)\n","\n","df['clean_text'] = df['clean_text'].str.lower()\n","df.head()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"train_test_set\"></a>\n","## 4. Create train and test dataset\n","\n","NOTE: Test dataset (30%) and Training dataset (70%) balanced (Stratified)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X = df['clean_text']\n","Y = df['sentiment']\n","\n","print(X.shape)\n","print(Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, stratify=Y)"]},{"cell_type":"markdown","metadata":{},"source":["NOTE: Machine Learning or Deep Learning models uses numeric values input. The Tf-Idf Text Feature Engineering (TFE) process will be used to transform the texts into vectors."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tfidf = TfidfVectorizer(max_features=2000, ngram_range=(2,3), sublinear_tf=True)\n","\n","X_train_tf = tfidf.fit_transform(X_train)\n","X_test_tf = tfidf.transform(X_test)\n","\n","print(Y.value_counts().shape)\n","print(X_train_tf.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["le = preprocessing.LabelEncoder()\n","\n","Y_train_le = le.fit_transform(list(Y_train))\n","Y_test_le = le.transform(list(Y_test))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"create_model\"></a>\n","## 5. Create a model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.svm import SVC\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.linear_model import LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Binary classifiers\n","# GradientBoostingClassifier\n","gradient_boost = GradientBoostingClassifier()\n","gradient_boost.fit(X_train_tf, Y_train_le)\n","Y_predict_gradient_boost = gradient_boost.predict(X_test_tf)\n","print('Gradient Boosting Classifier DONE!')\n","\n","# SVC -- taking too much time\n","# svc_model = SVC(gamma='auto', kernel='sigmoid', C=1.8, probability=True)\n","# svc_model.fit(X_train_tf, Y_train_le)\n","# Y_predict_svm = svc_model.predict(X_test_tf)\n","# print('Support Vector Machine(SVM) DONE!')\n","\n","# RandomForestClassifier\n","random_forest = RandomForestClassifier(n_estimators=10)\n","random_forest.fit(X_train_tf, Y_train_le)\n","Y_predict_random_forest = random_forest.predict(X_test_tf)\n","print('Random Forest Classifier DONE!')\n","\n","# KNeighborsClassifier\n","k_neighbors = KNeighborsClassifier()\n","k_neighbors.fit(X_train_tf, Y_train_le)\n","Y_predict_k_neighbors = k_neighbors.predict(X_test_tf)\n","print('K Nearest Neighbor Classifier DONE!')\n","\n","# LogisticRegression\n","logistic_regression = LogisticRegression(solver='lbfgs', penalty='l2', C=1.5)\n","logistic_regression.fit(X_train_tf, Y_train_le)\n","Y_predict_logistic_regression = logistic_regression.predict(X_test_tf)\n","print('Logistic Regression DONE!')"]},{"cell_type":"markdown","metadata":{},"source":["### 5.1 Model evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Gradient Boosting Classifier:  ', metrics.accuracy_score(Y_test_le, Y_predict_gradient_boost))\n","# print('Support Vector Machine(SVM):   ', metrics.accuracy_score(Y_test_le, Y_predict_svm))\n","print('Random Forest Classifier:      ', metrics.accuracy_score(Y_test_le, Y_predict_random_forest))\n","print('K Nearest Neighbor Classifier: ', metrics.accuracy_score(Y_test_le, Y_predict_k_neighbors))\n","print('Logistic Regression:           ', metrics.accuracy_score(Y_test_le, Y_predict_logistic_regression))"]},{"cell_type":"markdown","metadata":{},"source":["### 5.2 Resume of classification\n","\n","NOTE: Accuracy >= 0.70"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# print('Support vector machine(SVM):\\n {}\\n'.format(metrics.classification_report(Y_test_le, Y_predict_svm)))\n","print('Random Forest Classifier:\\n {}\\n'.format(metrics.classification_report(Y_test_le, Y_predict_random_forest)))\n","print('Logistic Regression:\\n {}\\n'.format(metrics.classification_report(Y_test_le, Y_predict_logistic_regression)))"]},{"cell_type":"markdown","metadata":{},"source":["### 5.3 - Logistic Regression\n","\n","NOTE: Best accuracy model confusion matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["logistic_regression_conf_matrix = metrics.confusion_matrix(Y_test_le, Y_predict_logistic_regression)\n","sns.heatmap(logistic_regression_conf_matrix, annot=True,  fmt='');\n","plt.title('Confusion matrix, Logistic Regression');"]},{"cell_type":"markdown","metadata":{},"source":["NOTE: Best accuracy model ROC curve"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fpr, tpr, thresholds = metrics.roc_curve(Y_test_le, Y_predict_logistic_regression)\n","auc = metrics.roc_auc_score(Y_test_le, Y_predict_logistic_regression)\n","\n","plt.subplots(figsize=(5,5))\n","plt.plot(fpr,tpr, label=\"AUC=\"+str(auc))\n","plt.plot(np.linspace(0, 1, 100),\n","         np.linspace(0, 1, 100),\n","         label='baseline',\n","         linestyle='--')\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.title('Receiver Operating Characteristic (ROC) Curve', fontsize=18)\n","plt.legend(loc=4)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 5.4 Model selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["X_train_final = tfidf.fit_transform(X)\n","Y_train_final = le.fit_transform(list(Y))\n","\n","print(X_train_final.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["lrc = LogisticRegression(solver='lbfgs', penalty='l2', C=1.5)\n","lrc.fit(X_train_final, Y_train_final)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"publish_model\"></a>\n","## 6. Publish the model"]},{"cell_type":"markdown","metadata":{},"source":["To authenticate to Watson Machine Learning in the IBM Cloud, you need api_key and service location.\n","\n","Using [IBM Cloud CLI](https://cloud.ibm.com/docs/cli/index.html) or directly through the IBM Cloud portal.\n","\n","Using IBM Cloud CLI:\n","\n","```\n","ibmcloud login\n","ibmcloud iam api-key-create API_KEY_NAME\n","```\n","\n","NOTE: To get the Service URL [Endpoint URLs section of the Watson Machine Learning docs](https://cloud.ibm.com/apidocs/machine-learning)."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["api_key = 'API_KEY'\n","location = 'LOCATION'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["wml_credentials = {\n","    \"apikey\": api_key,\n","    \"url\": location\n","}"]},{"cell_type":"markdown","metadata":{},"source":["### 6.1 Installing IBM Watson Machine Learning library\n","\n","NOTE: Documentation could be found [here](http://ibm-wml-api-pyclient.mybluemix.net/)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip install -U ibm-watson-machine-learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning import APIClient\n","\n","client = APIClient(wml_credentials)\n","print(client.version)"]},{"cell_type":"markdown","metadata":{},"source":["### 6.2 Publish model to project"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["project_id = 'PROJECT_ID'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.set.default_project(project_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sofware_spec_uid = client.software_specifications.get_id_by_name(\"runtime-22.1-py3.9\")\n","metadata = {\n","            client.repository.ModelMetaNames.NAME: 'Logistic Regression model to predict IMDB reviews',\n","            client.repository.ModelMetaNames.TYPE: 'scikit-learn_1.0',\n","            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid\n","}\n","\n","published_model = client.repository.store_model(model=lrc, meta_props=metadata)"]},{"cell_type":"markdown","metadata":{},"source":["### 6.3 Publish model to deployment space"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["space_id = 'SPACE_ID'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.set.default_space(space_id)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.spaces.list(limit=10)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["published_model = client.repository.store_model(model=lrc, meta_props=metadata)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["published_model_uid = client.repository.get_model_id(published_model)\n","model_details = client.repository.get_details(published_model_uid)\n","print(json.dumps(model_details, indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.repository.list_models()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# client.repository.delete('MODEL_ID')"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"deploy_model\"></a>\n","## 7. Deploy and Score\n","\n","NOTE: Deploy and score the model deployed at IBM Watson Machine Learning"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["metadata = {\n","    client.deployments.ConfigurationMetaNames.NAME: \"Deployment of IMDB reviews model\",\n","    client.deployments.ConfigurationMetaNames.ONLINE: {}\n","}\n","\n","created_deployment = client.deployments.create(published_model_uid, meta_props=metadata)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Get deployment UID and show details on the deployment\n","deployment_uid = client.deployments.get_uid(created_deployment)\n","client.deployments.get_details(deployment_uid)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["client.deployments.list()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# client.deployments.delete('GUID of deployed model')"]},{"cell_type":"markdown","metadata":{},"source":["### 7.1 Score model\n","\n","NOTE: Test the API created from IBM Watson Machine Learning."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# get scoring end point\n","scoring_endpoint = client.deployments.get_scoring_href(created_deployment)\n","print(scoring_endpoint)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# add some test data\n","scoring_payload = {\"input_data\": [\n","    {'values': X_test_tf.toarray()\n","    }]}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# score the model\n","predictions = client.deployments.score(deployment_uid, scoring_payload)\n","print('prediction',json.dumps(predictions, indent=2))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["Y_predict_final_model = []\n","for y in predictions['predictions'][0]['values']:\n","    Y_predict_final_model.append(y[0])\n","    \n","print('Final Model WML:\\n {}\\n'.format(metrics.classification_report(Y_test_le, Y_predict_final_model)))"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":1}
