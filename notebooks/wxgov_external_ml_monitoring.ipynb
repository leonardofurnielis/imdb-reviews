{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# watsonx.governance: Monitor external machine learning provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Set up the environment](#setup_environment)\n",
    "1. [Load and explore data](#load_explore_data)\n",
    "1. [Configure OpenScale](#configure_openscale)\n",
    "1. [Score the model](#score_model)\n",
    "1. [Configure monitors](#configure_monitors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade ibm-watson-machine-learning\n",
    "%pip install --upgrade ibm-watson-openscale\n",
    "%pip install --upgrade ibm_wos_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup_environment\"></a>\n",
    "## 1. Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WOS_API_KEY = \"WOS_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load_explore_data\"></a>\n",
    "## 2. Load and explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_training = pd.read_csv('../data/credit_risk_training.csv')\n",
    "df_training.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"explore_prepare_data\"></a>\n",
    "### 2.1. Construct the scoring payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scoring_payload(df, no_of_records_to_score = 1, cols_to_remove = []):\n",
    "    df = df.copy()\n",
    "\n",
    "    for col in cols_to_remove:\n",
    "        if col in df.columns:\n",
    "            del df[col] \n",
    "\n",
    "    fields = df.columns.tolist()\n",
    "    values = df[fields].values.tolist()\n",
    "\n",
    "    payload_scoring ={\"fields\": fields, \"values\": values[:no_of_records_to_score]}  \n",
    "    return payload_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload_scoring = get_scoring_payload(df_training, 1, [\"Risk\"])\n",
    "print(payload_scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Function to perform scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ml_scoring(payload_scoring,\n",
    "                      scoring_url):\n",
    "    header = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    scoring_response = requests.post(url=scoring_url, json=payload_scoring, headers=header, verify=False)\n",
    "\n",
    "    jsonify_scoring_response = scoring_response.json()\n",
    "    return jsonify_scoring_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Function to perform payload logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale.supporting_classes.payload_record import PayloadRecord\n",
    "\n",
    "def payload_logging(openscale_client, payload_data_set_id, payload_scoring, scoring_response):\n",
    "    scoring_id = str(uuid.uuid4())\n",
    "    records_list=[]\n",
    "    \n",
    "    pl_record = PayloadRecord(scoring_id=scoring_id, request=payload_scoring, response=scoring_response, response_time=int(460))\n",
    "    records_list.append(pl_record)\n",
    "    openscale_client.data_sets.store_records(data_set_id=payload_data_set_id, request_body=records_list)\n",
    "    \n",
    "    time.sleep(10)\n",
    "    pl_records_count = openscale_client.data_sets.get_records_count(payload_data_set_id)\n",
    "    print(\"Number of records in the payload logging table: {}\".format(pl_records_count))\n",
    "    return scoring_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configure_openscale\"></a>\n",
    "## 3. Configure OpenScale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watson_openscale import APIClient\n",
    "from ibm_watson_openscale.utils import *\n",
    "from ibm_watson_openscale.supporting_classes import *\n",
    "from ibm_watson_openscale.supporting_classes.enums import *\n",
    "from ibm_watson_openscale.base_classes.watson_open_scale_v2 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "authenticator = IAMAuthenticator(apikey=WOS_API_KEY)\n",
    "wos_client = APIClient(authenticator=authenticator)\n",
    "wos_client.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_marts.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_marts = wos_client.data_marts.list().result.data_marts\n",
    "if len(data_marts) == 0:\n",
    "    raise Exception(\"Missing data mart.\")\n",
    "data_mart_id=data_marts[0].metadata.id\n",
    "print('Using existing datamart: {}'.format(data_mart_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Add custom service provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREFIX = str(uuid.uuid4())[:8]\n",
    "\n",
    "SERVICE_PROVIDER_NAME = PREFIX + \" \" + \"External ML Provider\"\n",
    "SERVICE_PROVIDER_DESCRIPTION = PREFIX + \" \" + \"Added external WOS provider\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request_headers = { \"Content-Type\": \"application/json\" }\n",
    "MLCredentials = {}\n",
    "added_service_provider_result = wos_client.service_providers.add(\n",
    "        name=SERVICE_PROVIDER_NAME,\n",
    "        description=SERVICE_PROVIDER_DESCRIPTION,\n",
    "        service_type=ServiceTypes.CUSTOM_MACHINE_LEARNING,\n",
    "        request_headers=request_headers,\n",
    "        operational_space_id = \"production\",\n",
    "        credentials=MLCredentials,\n",
    "        background_mode=False\n",
    "    ).result\n",
    "\n",
    "service_provider_id = added_service_provider_result.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Service provider created with id: {}'.format(service_provider_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Add subscription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column=\"Risk\"\n",
    "\n",
    "wos_training_df = df_training.drop(label_column, axis=1)\n",
    "feature_columns = wos_training_df.columns.to_list()\n",
    "\n",
    "num_cols = wos_training_df._get_numeric_data().columns\n",
    "cat_columns = list(set(feature_columns) - set(num_cols))\n",
    "\n",
    "print(feature_columns)\n",
    "print(cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_request_headers = { \"Content-Type\": \"application/json\", \"X-Wos-Request\": True }\n",
    "\n",
    "SUBSCRIPTION_NAME = PREFIX + \" \" + \"External ML - All Monitors\"\n",
    "SCORING_ENDPOINT_URL = \"SCORING_ENDPOINT_URL\"\n",
    "\n",
    "ASSET_ID = str(uuid.uuid4())\n",
    "ASSET_DEPLOYMENT_ID = str(uuid.uuid4())\n",
    "\n",
    "# COS credentials (training data storage)\n",
    "COS_API_KEY_ID=\"COS_API_KEY_ID\"\n",
    "COS_RESOURCE_CRN=\"COS_RESOURCE_CRN\"\n",
    "COS_ENDPOINT=\"https://s3.us-east.cloud-object-storage.appdomain.cloud\"\n",
    "\n",
    "BUCKET_NAME=\"BUCKET_NAME\"\n",
    "FILE_NAME=\"FILE_NAME\"\n",
    "\n",
    "IAM_URL=\"https://iam.bluemix.net/oidc/token\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_details = wos_client.subscriptions.add(\n",
    "        data_mart_id=data_mart_id,\n",
    "        service_provider_id=service_provider_id,\n",
    "        asset=Asset(\n",
    "            asset_id=ASSET_ID,\n",
    "            name=SUBSCRIPTION_NAME,\n",
    "            url=SCORING_ENDPOINT_URL,\n",
    "            asset_type=AssetTypes.MODEL,\n",
    "            input_data_type=InputDataType.STRUCTURED,\n",
    "            problem_type=ProblemType.BINARY_CLASSIFICATION\n",
    "        ),\n",
    "        deployment=AssetDeploymentRequest(\n",
    "            deployment_id=ASSET_DEPLOYMENT_ID,\n",
    "            name=SUBSCRIPTION_NAME,\n",
    "            deployment_type= DeploymentTypes.ONLINE,\n",
    "            scoring_endpoint=ScoringEndpointRequest(\n",
    "                url=SCORING_ENDPOINT_URL,\n",
    "                request_headers=scoring_request_headers\n",
    "            )\n",
    "        ),\n",
    "        asset_properties=AssetPropertiesRequest(\n",
    "            label_column=label_column,\n",
    "            probability_fields=[\"probability\"],\n",
    "            prediction_field=\"prediction\",\n",
    "            feature_fields = feature_columns,\n",
    "            categorical_fields=cat_columns,\n",
    "            training_data_reference=TrainingDataReference(type=\"cos\",\n",
    "                                                          location=COSTrainingDataReferenceLocation(bucket = BUCKET_NAME,\n",
    "                                                                                                    file_name = FILE_NAME),\n",
    "                                                          connection=COSTrainingDataReferenceConnection.from_dict({\n",
    "                                                                        \"resource_instance_id\": COS_RESOURCE_CRN,\n",
    "                                                                        \"url\": COS_ENDPOINT,\n",
    "                                                                        \"api_key\": COS_API_KEY_ID,\n",
    "                                                                        \"iam_url\": IAM_URL}))\n",
    "        )\n",
    "    ).result\n",
    "subscription_id = subscription_details.metadata.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Subscription created with id: {}'.format(subscription_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "time.sleep(10)\n",
    "payload_data_set_id = None\n",
    "payload_data_set_id = wos_client.data_sets.list(type=DataSetTypes.PAYLOAD_LOGGING, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result.data_sets[0].metadata.id\n",
    "if payload_data_set_id is None:\n",
    "    print(\"Payload data set not found. Please check subscription status.\")\n",
    "else:\n",
    "    print('Payload data set id: {}'.format(payload_data_set_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Update subscription scoring endpoint\n",
    "\n",
    "NOTE: When working with external models you're responsible for performing payload logging. Now, you can use your `payload_data_set_id` to deploy your model scoring endpoint. After that, you can update your subscription scoring endpoint. PERFORM THIS PROCESS BEFORE SETTING UP THE MONITORS!\n",
    "\n",
    "Python payload logging example: https://github.com/leonardofurnielis/sample-model-container/blob/wos-payload-logging/main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.subscriptions.update(subscription_id=subscription_id, patch_document=[{\n",
    "    \"op\": \"replace\",\n",
    "    \"path\": \"/asset/url\",\n",
    "    \"value\": \"SCORING_ENDPOINT_URL\",\n",
    "},\n",
    "{\n",
    "    \"op\": \"replace\",\n",
    "    \"path\": \"/deployment/scoring_endpoint/url\",\n",
    "    \"value\": \"SCORING_ENDPOINT_URL\"}]).result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"score_model\"></a>\n",
    "## 4. Score the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_records_to_score = 50\n",
    "payload_scoring = get_scoring_payload(df_training, no_of_records_to_score, [label_column])\n",
    "print(payload_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_response = custom_ml_scoring(payload_scoring, SCORING_ENDPOINT_URL)\n",
    "print(scoring_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring_id = payload_logging(openscale_client=wos_client,\n",
    "#                              payload_data_set_id=payload_data_set_id, \n",
    "#                              payload_scoring=payload_scoring, \n",
    "#                              scoring_response=scoring_response)\n",
    "# print(scoring_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"configure_monitors\"></a>\n",
    "## 5. Configure monitors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Quality monitoring and feedback logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = Target(\n",
    "        target_type=TargetTypes.SUBSCRIPTION,\n",
    "        target_id=subscription_id\n",
    ")\n",
    "parameters = {\n",
    "    \"min_feedback_data_size\": 50\n",
    "}\n",
    "thresholds = [\n",
    "                {\n",
    "                    \"metric_id\": wos_client.monitor_definitions.MONITORS.QUALITY.METRIC.AREA_UNDER_ROC,\n",
    "                    \"type\": \"lower_limit\",\n",
    "                    \"value\": .85\n",
    "                },\n",
    "                {\n",
    "                    \"metric_id\": wos_client.monitor_definitions.MONITORS.QUALITY.METRIC.ACCURACY,\n",
    "                    \"type\": \"lower_limit\",\n",
    "                    \"value\": .75\n",
    "                },\n",
    "                  {\n",
    "                    \"metric_id\": wos_client.monitor_definitions.MONITORS.QUALITY.METRIC.PRECISION,\n",
    "                    \"type\": \"lower_limit\",\n",
    "                    \"value\": .90\n",
    "                },\n",
    "                     {\n",
    "                    \"metric_id\": wos_client.monitor_definitions.MONITORS.QUALITY.METRIC.RECALL,\n",
    "                    \"type\": \"lower_limit\",\n",
    "                    \"value\": .70\n",
    "                }\n",
    "            ]\n",
    "quality_monitor_details = wos_client.monitor_instances.create(\n",
    "    data_mart_id=data_mart_id,\n",
    "    background_mode=False,\n",
    "    monitor_definition_id=wos_client.monitor_definitions.MONITORS.QUALITY.ID,\n",
    "    target=target,\n",
    "    parameters=parameters,\n",
    "    thresholds=thresholds\n",
    ").result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_monitor_instance_id = quality_monitor_details.metadata.id\n",
    "print('Quality monitor id: {}'.format(quality_monitor_instance_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/credit_risk_test.csv')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_records_to_eval = 50\n",
    "feedback_columns = df_test.columns.to_list()\n",
    "\n",
    "feedback_data = []\n",
    "\n",
    "for value in df_test.values[:no_of_records_to_eval]:\n",
    "\n",
    "    dict_item = {}\n",
    "    for i in range(len(feedback_columns)):\n",
    "        dict_item[feedback_columns[i]] = value[i]\n",
    "    \n",
    "    feedback_data.append(dict_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feedback_dataset_id = None\n",
    "feedback_dataset = wos_client.data_sets.list(type=DataSetTypes.FEEDBACK, \n",
    "                                                target_target_id=subscription_id, \n",
    "                                                target_target_type=TargetTypes.SUBSCRIPTION).result\n",
    "feedback_dataset_id = feedback_dataset.data_sets[0].metadata.id\n",
    "if feedback_dataset_id is None:\n",
    "    print(\"Feedback data set not found. Please check quality monitor status.\")\n",
    "\n",
    "print('Feedback data set id: {}'.format(feedback_dataset_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store feedback data into feedback dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_sets.store_records(feedback_dataset_id, request_body=feedback_data, background_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify the number of feedback data into feedback dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wos_client.data_sets.get_records_count(data_set_id=feedback_dataset_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run quality monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_details = wos_client.monitor_instances.run(monitor_instance_id=quality_monitor_instance_id, background_mode=False).result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
